import json
import logging
from typing import Any, Dict, Union

# é…ç½®æ—¥å¿—
logger = logging.getLogger('json_merger')

class JSONMerger:
    """JSONåˆå¹¶å™¨ - ç”¨äºåˆå¹¶GLBPointCloudBoundså’ŒGLBPointCloudOriginAdjusterçš„è¾“å‡ºæ•°æ®"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "json_data_1": ("STRING", {
                    "tooltip": "ç¬¬ä¸€ä¸ªJSONæ•°æ®ï¼šæ¥è‡ªGLBPointCloudBoundsæˆ–GLBPointCloudOriginAdjusterçš„è¾“å‡ºã€‚æ”¯æŒåŒ…å«nameã€scaleã€positionç­‰å­—æ®µçš„JSONæ ¼å¼æ•°æ®"
                }),
                "json_data_2": ("STRING", {
                    "tooltip": "ç¬¬äºŒä¸ªJSONæ•°æ®ï¼šæ¥è‡ªGLBPointCloudBoundsæˆ–GLBPointCloudOriginAdjusterçš„è¾“å‡ºã€‚æ”¯æŒåŒ…å«nameã€scaleã€positionç­‰å­—æ®µçš„JSONæ ¼å¼æ•°æ®"
                }),
            },
            "optional": {
                "json_data_3": ("STRING", {
                    "tooltip": "ç¬¬ä¸‰ä¸ªJSONæ•°æ®ï¼ˆå¯é€‰ï¼‰ï¼šé¢å¤–çš„JSONæ•°æ®ï¼Œç”¨äºä¸‰è·¯åˆå¹¶ã€‚ç•™ç©ºåˆ™åªåˆå¹¶å‰ä¸¤ä¸ªæ•°æ®"
                }),
                "merge_mode": (["smart_merge", "array_concat"], {
                    "default": "smart_merge",
                    "tooltip": "åˆå¹¶æ¨¡å¼ï¼šsmart_merge=æ™ºèƒ½åˆå¹¶ï¼ˆç›¸åŒnameåˆå¹¶å­—æ®µï¼Œä¸åŒnameç”¨é€—å·è¿æ¥ï¼‰ï¼›array_concat=æ•°ç»„è¿æ¥ï¼ˆæ‰€æœ‰æ•°æ®æ”¾å…¥æ•°ç»„ï¼‰"
                }),
            }
        }

    RETURN_TYPES = (
        "STRING",    # åˆå¹¶åçš„JSONå­—ç¬¦ä¸²
    )
    RETURN_NAMES = (
        "merged_json",
    )
    OUTPUT_TOOLTIPS = [
        "åˆå¹¶åçš„JSONæ•°æ®ï¼šæ ¹æ®nameå­—æ®µæ™ºèƒ½åˆå¹¶æˆ–è¿æ¥å¤šä¸ªJSONå¯¹è±¡çš„ç»“æœ",
    ]
    OUTPUT_NODE = True
    FUNCTION = "merge_json_data"
    CATEGORY = "ğŸ’ƒVVL/JSON Processing"

    def merge_json_data(self,
                       json_data_1: str,
                       json_data_2: str,
                       json_data_3: str = "",
                       merge_mode: str = "smart_merge"):
        """
        åˆå¹¶å¤šä¸ªJSONæ•°æ®
        """
        
        processing_log = []
        processing_log.append("å¼€å§‹JSONæ•°æ®åˆå¹¶...")
        
        try:
            # è§£æè¾“å…¥çš„JSONæ•°æ®
            json_objects = []
            
            # è§£æç¬¬ä¸€ä¸ªJSON
            if json_data_1.strip():
                try:
                    obj1 = json.loads(json_data_1.strip())
                    json_objects.append(obj1)
                    processing_log.append(f"è§£æJSONæ•°æ®1æˆåŠŸ: {self._get_object_summary(obj1)}")
                except json.JSONDecodeError as e:
                    error_msg = f"JSONæ•°æ®1è§£æå¤±è´¥: {str(e)}"
                    processing_log.append(f"é”™è¯¯: {error_msg}")
                    return (json.dumps({"error": error_msg}, indent=2),)
            
            # è§£æç¬¬äºŒä¸ªJSON
            if json_data_2.strip():
                try:
                    obj2 = json.loads(json_data_2.strip())
                    json_objects.append(obj2)
                    processing_log.append(f"è§£æJSONæ•°æ®2æˆåŠŸ: {self._get_object_summary(obj2)}")
                except json.JSONDecodeError as e:
                    error_msg = f"JSONæ•°æ®2è§£æå¤±è´¥: {str(e)}"
                    processing_log.append(f"é”™è¯¯: {error_msg}")
                    return (json.dumps({"error": error_msg}, indent=2),)
            
            # è§£æç¬¬ä¸‰ä¸ªJSONï¼ˆå¯é€‰ï¼‰
            if json_data_3.strip():
                try:
                    obj3 = json.loads(json_data_3.strip())
                    json_objects.append(obj3)
                    processing_log.append(f"è§£æJSONæ•°æ®3æˆåŠŸ: {self._get_object_summary(obj3)}")
                except json.JSONDecodeError as e:
                    error_msg = f"JSONæ•°æ®3è§£æå¤±è´¥: {str(e)}"
                    processing_log.append(f"é”™è¯¯: {error_msg}")
                    return (json.dumps({"error": error_msg}, indent=2),)
            
            if not json_objects:
                error_msg = "æ²¡æœ‰æœ‰æ•ˆçš„JSONæ•°æ®è¾“å…¥"
                processing_log.append(f"é”™è¯¯: {error_msg}")
                return (json.dumps({"error": error_msg}, indent=2),)
            
            if len(json_objects) == 1:
                processing_log.append("åªæœ‰ä¸€ä¸ªæœ‰æ•ˆJSONå¯¹è±¡ï¼Œç›´æ¥è¿”å›")
                result = json_objects[0]
            else:
                # æ ¹æ®åˆå¹¶æ¨¡å¼å¤„ç†
                if merge_mode == "smart_merge":
                    result = self._smart_merge(json_objects, processing_log)
                else:  # array_concat
                    result = self._array_concat(json_objects, processing_log)
            
            # ç”Ÿæˆæœ€ç»ˆçš„JSONå­—ç¬¦ä¸²
            merged_json = json.dumps(result, indent=2, ensure_ascii=False)
            
            processing_log.append("JSONæ•°æ®åˆå¹¶å®Œæˆ!")
            processing_log.append(f"æœ€ç»ˆç»“æœ: {self._get_object_summary(result)}")
            
            return (merged_json,)
                
        except Exception as e:
            error_msg = f"åˆå¹¶JSONæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg)
            processing_log.append(f"é”™è¯¯: {error_msg}")
            import traceback
            traceback.print_exc()
            return (json.dumps({"error": error_msg}, indent=2),)
    
    def _smart_merge(self, json_objects: list, processing_log: list) -> Union[Dict, list]:
        """
        æ™ºèƒ½åˆå¹¶ï¼šç›¸åŒnameçš„å¯¹è±¡åˆå¹¶å­—æ®µï¼Œä¸åŒnameçš„å¯¹è±¡ç”¨æ•°ç»„å½¢å¼è¿”å›
        """
        processing_log.append("ä½¿ç”¨æ™ºèƒ½åˆå¹¶æ¨¡å¼...")
        
        # æŒ‰nameå­—æ®µåˆ†ç»„
        name_groups = {}
        unnamed_objects = []
        
        for i, obj in enumerate(json_objects):
            if isinstance(obj, dict):
                name = obj.get("name")
                if name:
                    if name not in name_groups:
                        name_groups[name] = []
                    name_groups[name].append(obj)
                    processing_log.append(f"å¯¹è±¡{i+1}å½’å…¥ç»„ '{name}'")
                else:
                    unnamed_objects.append(obj)
                    processing_log.append(f"å¯¹è±¡{i+1}æ²¡æœ‰nameå­—æ®µï¼Œå½’å…¥æœªå‘½åç»„")
            else:
                unnamed_objects.append(obj)
                processing_log.append(f"å¯¹è±¡{i+1}ä¸æ˜¯å­—å…¸ç±»å‹ï¼Œå½’å…¥æœªå‘½åç»„")
        
        # åˆå¹¶ç»“æœ
        merged_results = []
        
        # å¤„ç†æœ‰nameçš„ç»„
        for name, group_objects in name_groups.items():
            if len(group_objects) == 1:
                # åªæœ‰ä¸€ä¸ªå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                merged_results.append(group_objects[0])
                processing_log.append(f"ç»„ '{name}' åªæœ‰ä¸€ä¸ªå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨")
            else:
                # å¤šä¸ªå¯¹è±¡ï¼Œåˆå¹¶å­—æ®µ
                merged_obj = {"name": name}
                for obj in group_objects:
                    for key, value in obj.items():
                        if key != "name":  # è·³è¿‡nameå­—æ®µ
                            if key not in merged_obj:
                                merged_obj[key] = value
                            else:
                                # å¦‚æœå­—æ®µå·²å­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨éç©ºå€¼
                                if not merged_obj[key] and value:
                                    merged_obj[key] = value
                
                merged_results.append(merged_obj)
                processing_log.append(f"ç»„ '{name}' åˆå¹¶äº† {len(group_objects)} ä¸ªå¯¹è±¡")
        
        # æ·»åŠ æœªå‘½åå¯¹è±¡
        merged_results.extend(unnamed_objects)
        if unnamed_objects:
            processing_log.append(f"æ·»åŠ äº† {len(unnamed_objects)} ä¸ªæœªå‘½åå¯¹è±¡")
        
        # è¿”å›ç»“æœ
        if len(merged_results) == 1:
            processing_log.append("åˆå¹¶ç»“æœä¸ºå•ä¸ªå¯¹è±¡")
            return merged_results[0]
        else:
            processing_log.append(f"åˆå¹¶ç»“æœä¸º {len(merged_results)} ä¸ªå¯¹è±¡çš„æ•°ç»„")
            return merged_results
    
    def _array_concat(self, json_objects: list, processing_log: list) -> list:
        """
        æ•°ç»„è¿æ¥ï¼šå°†æ‰€æœ‰å¯¹è±¡æ”¾å…¥ä¸€ä¸ªæ•°ç»„
        """
        processing_log.append("ä½¿ç”¨æ•°ç»„è¿æ¥æ¨¡å¼...")
        processing_log.append(f"å°† {len(json_objects)} ä¸ªå¯¹è±¡è¿æ¥ä¸ºæ•°ç»„")
        return json_objects
    
    def _get_object_summary(self, obj: Any) -> str:
        """
        è·å–å¯¹è±¡çš„ç®€è¦æè¿°
        """
        if isinstance(obj, dict):
            keys = list(obj.keys())
            name = obj.get("name", "æœªå‘½å")
            return f"å­—å…¸å¯¹è±¡ name='{name}', å­—æ®µ=[{', '.join(keys)}]"
        elif isinstance(obj, list):
            return f"æ•°ç»„å¯¹è±¡ï¼ŒåŒ…å« {len(obj)} ä¸ªå…ƒç´ "
        else:
            return f"å…¶ä»–ç±»å‹: {type(obj).__name__}"

class UESceneGenerator:
    """UEåœºæ™¯ç”Ÿæˆå™¨ - å°†JSONMergerçš„è¾“å‡ºè½¬æ¢ä¸ºUEåœºæ™¯é…ç½®æ ¼å¼"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "merged_json": ("*", {
                    "tooltip": "åˆå¹¶åçš„JSONæ•°æ®ï¼šæ¥è‡ªJSONMergerçš„è¾“å‡ºï¼ŒåŒ…å«nameã€positionã€scaleç­‰å­—æ®µçš„JSONæ•°æ®ï¼Œæ”¯æŒSTRING/LIST/DICTç±»å‹"
                }),
            },
            "optional": {
                "camera_position": ("STRING", {
                    "default": "[-1000, 0, 100]",
                    "tooltip": "ç›¸æœºä½ç½®ï¼šUEåœºæ™¯ä¸­ç›¸æœºçš„ä¸–ç•Œåæ ‡ä½ç½® [X, Y, Z]ï¼Œé»˜è®¤ä¸º[-1000, 0, 100]"
                }),
                "camera_rotation": ("STRING", {
                    "default": "[-12, 0, 0]",
                    "tooltip": "ç›¸æœºæ—‹è½¬ï¼šUEåœºæ™¯ä¸­ç›¸æœºçš„æ—‹è½¬è§’åº¦ [Pitch, Yaw, Roll]ï¼Œé»˜è®¤ä¸º[-12, 0, 0]"
                }),
                "camera_fov": ("FLOAT", {
                    "default": 58.53, "min": 1.0, "max": 179.0, "step": 0.1,
                    "tooltip": "ç›¸æœºè§†é‡è§’åº¦ï¼šUEåœºæ™¯ä¸­ç›¸æœºçš„è§†é‡è§’åº¦(FOV)ï¼Œé»˜è®¤ä¸º58.53åº¦ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ•°å€¼å‚æ•°ï¼Œä¸è¦è¿æ¥æ•°ç»„è¾“å…¥ï¼"
                }),
                "default_object_rotation": ("STRING", {
                    "default": "[0, 0, 0]",
                    "tooltip": "é»˜è®¤ç‰©ä½“æ—‹è½¬ï¼šå½“è¾“å…¥æ•°æ®ä¸­æ²¡æœ‰rotationå­—æ®µæ—¶ä½¿ç”¨çš„é»˜è®¤æ—‹è½¬å€¼ [Pitch, Yaw, Roll]"
                }),
                "scale_axis": (["XYZ", "X", "Y", "Z", "XY", "XZ", "YZ"], {
                    "default": "XYZ",
                    "tooltip": "ç¼©æ”¾è½´å‘ï¼šé€‰æ‹©å¯¹ç‰©ä½“scaleè¿›è¡Œç¼©æ”¾çš„è½´å‘ã€‚XYZ=å…¨è½´ï¼ŒX/Y/Z=å•è½´ï¼ŒXY/XZ/YZ=åŒè½´"
                }),
                "scale_multiplier": ("FLOAT", {
                    "default": 1.0, "min": 0.001, "max": 1000.0, "step": 0.1,
                    "tooltip": "ç¼©æ”¾å€æ•°ï¼šå¯¹é€‰å®šè½´å‘çš„scaleå€¼è¿›è¡Œç¼©æ”¾çš„å€æ•°ï¼Œç”¨äºè°ƒæ•´ç‰©ä½“å¤§å°åˆ°åˆé€‚çš„UEå•ä½ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ•°å€¼å‚æ•°ï¼Œä¸è¦è¿æ¥æ•°ç»„è¾“å…¥ï¼"
                }),
                "position_axis": (["XYZ", "X", "Y", "Z", "XY", "XZ", "YZ"], {
                    "default": "Z",
                    "tooltip": "ä½ç½®è½´å‘ï¼šé€‰æ‹©å¯¹ç‰©ä½“positionè¿›è¡Œç¼©æ”¾çš„è½´å‘ã€‚XYZ=å…¨è½´ï¼ŒX/Y/Z=å•è½´ï¼ŒXY/XZ/YZ=åŒè½´"
                }),
                "position_multiplier": ("FLOAT", {
                    "default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.1,
                    "tooltip": "ä½ç½®å€æ•°ï¼šå¯¹é€‰å®šè½´å‘çš„positionå€¼è¿›è¡Œç¼©æ”¾çš„å€æ•°ï¼Œç”¨äºè°ƒæ•´ç‰©ä½“ä½ç½®åˆ°åˆé€‚çš„UEå•ä½ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ•°å€¼å‚æ•°ï¼Œä¸è¦è¿æ¥æ•°ç»„è¾“å…¥ï¼"
                }),
                "recenter_scene": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦è‡ªåŠ¨å°†æ‰€æœ‰ç‰©ä½“æ•´ä½“å¹³ç§»ï¼Œä½¿åœºæ™¯ä¸­å¿ƒ(è´¨å¿ƒ)ä½äºåŸç‚¹(0,0,0)ã€‚å¼€å¯åï¼Œä¸å½±å“ç‰©ä½“é—´ç›¸å¯¹ä½ç½®å’Œå¤§å°ã€‚"
                }),
                "flip_y_axis": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦ç¿»è½¬Yè½´åæ ‡ï¼ˆYå€¼å–åï¼‰ä»¥é€‚é…UEåæ ‡ä½“ç³»ã€‚å¼€å¯åï¼Œæ‰€æœ‰positionçš„Yå€¼ä¼šå–åï¼Œå…¶ä»–è½´ä¸å˜ã€‚"
                }),
            }
        }

    RETURN_TYPES = (
        "STRING",    # UEåœºæ™¯é…ç½®JSON
    )
    RETURN_NAMES = (
        "ue_scene_json",
    )
    OUTPUT_TOOLTIPS = [
        "UEåœºæ™¯é…ç½®JSONï¼šç¬¦åˆUEå¯¼å…¥æ ¼å¼çš„å®Œæ•´åœºæ™¯é…ç½®ï¼ŒåŒ…å«ç›¸æœºè®¾ç½®å’Œç‰©ä½“åˆ—è¡¨",
    ]
    OUTPUT_NODE = True
    FUNCTION = "generate_ue_scene"
    CATEGORY = "ğŸ’ƒVVL/UE Integration"

    def generate_ue_scene(self,
                         merged_json,
                         camera_position: str = "[-1000, 0, 100]",
                         camera_rotation: str = "[-12, 0, 0]",
                         camera_fov = 58.53,
                         default_object_rotation: str = "[0, 0, 0]",
                         scale_axis: str = "XYZ",
                         scale_multiplier = 1.0,
                         position_axis: str = "XYZ",
                         position_multiplier = 0.0,
                         recenter_scene: bool = False,
                         flip_y_axis: bool = True):
        """
        å°†åˆå¹¶çš„JSONæ•°æ®è½¬æ¢ä¸ºUEåœºæ™¯é…ç½®æ ¼å¼
        """
        
        processing_log = []
        processing_log.append("å¼€å§‹ç”ŸæˆUEåœºæ™¯é…ç½®...")
        
        # å‚æ•°éªŒè¯å’Œä¿®å¤
        try:
            # ä¿®å¤å¯èƒ½é”™è¯¯è¿æ¥çš„å‚æ•°
            if isinstance(camera_fov, str):
                processing_log.append(f"è­¦å‘Š: camera_fovå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°å­—ç¬¦ä¸²'{camera_fov}')ï¼Œä½¿ç”¨é»˜è®¤å€¼58.53")
                camera_fov = 58.53
            elif not isinstance(camera_fov, (int, float)):
                processing_log.append(f"è­¦å‘Š: camera_fovå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°{type(camera_fov).__name__})ï¼Œä½¿ç”¨é»˜è®¤å€¼58.53")
                camera_fov = 58.53
            
            if isinstance(scale_multiplier, str):
                processing_log.append(f"è­¦å‘Š: scale_multiplierå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°å­—ç¬¦ä¸²'{scale_multiplier}')ï¼Œä½¿ç”¨é»˜è®¤å€¼1.0")
                scale_multiplier = 1.0
            elif not isinstance(scale_multiplier, (int, float)):
                processing_log.append(f"è­¦å‘Š: scale_multiplierå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°{type(scale_multiplier).__name__})ï¼Œä½¿ç”¨é»˜è®¤å€¼1.0")
                scale_multiplier = 1.0
                
            if isinstance(position_multiplier, str):
                processing_log.append(f"è­¦å‘Š: position_multiplierå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°å­—ç¬¦ä¸²'{position_multiplier}')ï¼Œä½¿ç”¨é»˜è®¤å€¼0.0")
                position_multiplier = 0.0
            elif not isinstance(position_multiplier, (int, float)):
                processing_log.append(f"è­¦å‘Š: position_multiplierå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°{type(position_multiplier).__name__})ï¼Œä½¿ç”¨é»˜è®¤å€¼0.0")
                position_multiplier = 0.0
            
            if not isinstance(recenter_scene, bool):
                processing_log.append(f"è­¦å‘Š: recenter_sceneå‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°{type(recenter_scene).__name__})ï¼Œä½¿ç”¨é»˜è®¤å€¼False")
                recenter_scene = False
            
            if not isinstance(flip_y_axis, bool):
                processing_log.append(f"è­¦å‘Š: flip_y_axiså‚æ•°ç±»å‹é”™è¯¯(æ”¶åˆ°{type(flip_y_axis).__name__})ï¼Œä½¿ç”¨é»˜è®¤å€¼True")
                flip_y_axis = True
            
            # ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†…
            camera_fov = max(1.0, min(179.0, float(camera_fov)))
            scale_multiplier = max(0.001, min(1000.0, float(scale_multiplier)))
            position_multiplier = max(0.0, min(1000.0, float(position_multiplier)))
            
            # éªŒè¯è½´å‘å‚æ•°
            valid_axes = ["XYZ", "X", "Y", "Z", "XY", "XZ", "YZ"]
            if scale_axis not in valid_axes:
                processing_log.append(f"è­¦å‘Š: scale_axiså‚æ•°æ— æ•ˆ('{scale_axis}')ï¼Œä½¿ç”¨é»˜è®¤å€¼'XYZ'")
                scale_axis = "XYZ"
            if position_axis not in valid_axes:
                processing_log.append(f"è­¦å‘Š: position_axiså‚æ•°æ— æ•ˆ('{position_axis}')ï¼Œä½¿ç”¨é»˜è®¤å€¼'XYZ'")
                position_axis = "XYZ"
            
            processing_log.append(f"å‚æ•°éªŒè¯å®Œæˆ: camera_fov={camera_fov}")
            processing_log.append(f"ç¼©æ”¾è®¾ç½®: {scale_axis}è½´, å€æ•°={scale_multiplier}")
            processing_log.append(f"ä½ç½®è®¾ç½®: {position_axis}è½´, å€æ•°={position_multiplier}")
            processing_log.append(f"åæ ‡ç³»è®¾ç½®: Yè½´ç¿»è½¬={'å¼€å¯' if flip_y_axis else 'å…³é—­'}, åœºæ™¯å±…ä¸­={'å¼€å¯' if recenter_scene else 'å…³é—­'}")
            
        except Exception as e:
            processing_log.append(f"å‚æ•°éªŒè¯å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            camera_fov = 58.53
            scale_multiplier = 1.0
            position_multiplier = 0.0
            scale_axis = "XYZ"
            position_axis = "XYZ"
            recenter_scene = False
        
        try:
            # å¤„ç†è¾“å…¥çš„åˆå¹¶JSONæ•°æ®ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–ç›´æ¥çš„æ•°æ®ï¼‰
            if isinstance(merged_json, str):
                # å­—ç¬¦ä¸²è¾“å…¥ï¼Œéœ€è¦è§£æ
                if not merged_json.strip():
                    error_msg = "åˆå¹¶JSONæ•°æ®ä¸ºç©º"
                    processing_log.append(f"é”™è¯¯: {error_msg}")
                    return (json.dumps({"error": error_msg}, indent=2),)
                
                try:
                    merged_data = json.loads(merged_json.strip())
                    processing_log.append("å­—ç¬¦ä¸²JSONæ•°æ®è§£ææˆåŠŸ")
                except json.JSONDecodeError as e:
                    error_msg = f"JSONæ•°æ®è§£æå¤±è´¥: {str(e)}"
                    processing_log.append(f"é”™è¯¯: {error_msg}")
                    return (json.dumps({"error": error_msg}, indent=2),)
            elif isinstance(merged_json, (list, dict)):
                # ç›´æ¥çš„æ•°æ®ç»“æ„è¾“å…¥
                merged_data = merged_json
                processing_log.append(f"ç›´æ¥æ•°æ®è¾“å…¥: {type(merged_json).__name__}")
                
                # è¯¦ç»†åˆ†æè¾“å…¥ç»“æ„
                if isinstance(merged_json, list):
                    processing_log.append(f"åˆ—è¡¨åŒ…å« {len(merged_json)} ä¸ªå…ƒç´ :")
                    for i, item in enumerate(merged_json):
                        if isinstance(item, dict):
                            keys = list(item.keys())
                            processing_log.append(f"  å…ƒç´ {i}: dict with keys {keys}")
                        elif isinstance(item, str):
                            preview = item[:100] + "..." if len(item) > 100 else item
                            processing_log.append(f"  å…ƒç´ {i}: string '{preview}'")
                        else:
                            processing_log.append(f"  å…ƒç´ {i}: {type(item).__name__}")
                            
            else:
                error_msg = f"ä¸æ”¯æŒçš„è¾“å…¥æ•°æ®ç±»å‹: {type(merged_json).__name__}"
                processing_log.append(f"é”™è¯¯: {error_msg}")
                return (json.dumps({"error": error_msg}, indent=2),)
            
            # è§£æç›¸æœºå‚æ•°
            try:
                cam_pos = json.loads(camera_position)
                cam_rot = json.loads(camera_rotation)
                default_rot = json.loads(default_object_rotation)
                
                if not isinstance(cam_pos, list) or len(cam_pos) != 3:
                    raise ValueError("ç›¸æœºä½ç½®å¿…é¡»æ˜¯åŒ…å«3ä¸ªæ•°å€¼çš„æ•°ç»„")
                if not isinstance(cam_rot, list) or len(cam_rot) != 3:
                    raise ValueError("ç›¸æœºæ—‹è½¬å¿…é¡»æ˜¯åŒ…å«3ä¸ªæ•°å€¼çš„æ•°ç»„")
                if not isinstance(default_rot, list) or len(default_rot) != 3:
                    raise ValueError("é»˜è®¤æ—‹è½¬å¿…é¡»æ˜¯åŒ…å«3ä¸ªæ•°å€¼çš„æ•°ç»„")
                    
                processing_log.append(f"ç›¸æœºå‚æ•°è§£ææˆåŠŸ: ä½ç½®{cam_pos}, æ—‹è½¬{cam_rot}, FOV{camera_fov}")
                
            except (json.JSONDecodeError, ValueError) as e:
                error_msg = f"ç›¸æœºå‚æ•°è§£æå¤±è´¥: {str(e)}"
                processing_log.append(f"é”™è¯¯: {error_msg}")
                return (json.dumps({"error": error_msg}, indent=2),)
            
            # åˆ›å»ºUEåœºæ™¯é…ç½®åŸºç¡€ç»“æ„
            ue_scene = {
                "camera": {
                    "position": cam_pos,
                    "rotation": cam_rot,
                    "fov": camera_fov
                },
                "objects": []
            }
            
            # å¤„ç†ç‰©ä½“æ•°æ®
            objects_processed = 0
            
            def process_data_item(data_item, item_name=""):
                """é€’å½’å¤„ç†æ•°æ®é¡¹ï¼Œæ”¯æŒåµŒå¥—ç»“æ„"""
                nonlocal objects_processed
                
                if isinstance(data_item, dict):
                    # å•ä¸ªç‰©ä½“å­—å…¸
                    ue_object = self._convert_to_ue_object(
                        data_item, default_rot, scale_axis, scale_multiplier, 
                        position_axis, position_multiplier, flip_y_axis, processing_log
                    )
                    if ue_object:
                        ue_scene["objects"].append(ue_object)
                        objects_processed += 1
                        
                elif isinstance(data_item, list):
                    # æ•°ç»„ï¼Œé€’å½’å¤„ç†æ¯ä¸ªå…ƒç´ 
                    for i, sub_item in enumerate(data_item):
                        sub_name = f"{item_name}[{i}]" if item_name else f"item_{i}"
                        process_data_item(sub_item, sub_name)
                        
                elif isinstance(data_item, str):
                    # å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                    try:
                        parsed_item = json.loads(data_item)
                        processing_log.append(f"è§£æåµŒå¥—JSONå­—ç¬¦ä¸²: {item_name}")
                        process_data_item(parsed_item, f"{item_name}_parsed")
                    except json.JSONDecodeError:
                        processing_log.append(f"è·³è¿‡æ— æ³•è§£æçš„å­—ç¬¦ä¸²: {item_name} = '{data_item[:50]}...'")
                        
                else:
                    processing_log.append(f"è·³è¿‡ä¸æ”¯æŒçš„æ•°æ®ç±»å‹ {item_name}: {type(data_item).__name__}")
            
            # å¼€å§‹å¤„ç†æ•°æ®
            if isinstance(merged_data, (dict, list)):
                processing_log.append(f"å¼€å§‹å¤„ç†è¾“å…¥æ•°æ®ç±»å‹: {type(merged_data).__name__}")
                process_data_item(merged_data, "root")
            else:
                error_msg = f"ä¸æ”¯æŒçš„åˆå¹¶æ•°æ®ç±»å‹: {type(merged_data).__name__}"
                processing_log.append(f"é”™è¯¯: {error_msg}")
                return (json.dumps({"error": error_msg}, indent=2),)
            
            processing_log.append(f"æˆåŠŸå¤„ç† {objects_processed} ä¸ªç‰©ä½“")
            
            # -------------------------------------------------
            # åœºæ™¯æ•´ä½“å±…ä¸­: å°†æ‰€æœ‰ç‰©ä½“è´¨å¿ƒç§»åŠ¨åˆ°åŸç‚¹
            # -------------------------------------------------
            if recenter_scene and objects_processed > 0:
                # è®¡ç®—è´¨å¿ƒ
                sum_x = sum(o["position"][0] for o in ue_scene["objects"])
                sum_y = sum(o["position"][1] for o in ue_scene["objects"])
                sum_z = sum(o["position"][2] for o in ue_scene["objects"])
                centroid = [sum_x / objects_processed, sum_y / objects_processed, sum_z / objects_processed]
                processing_log.append(f"åœºæ™¯è´¨å¿ƒ: {centroid}")
                
                # æ£€æŸ¥ç‰©ä½“ä½ç½®æ˜¯å¦æœ‰æ˜æ˜¾å·®å¼‚ï¼ˆé¿å…æ‰€æœ‰ç‰©ä½“éƒ½ç§»åŠ¨åˆ°åŸç‚¹çš„é—®é¢˜ï¼‰
                positions = [o["position"] for o in ue_scene["objects"]]
                min_x = min(pos[0] for pos in positions)
                max_x = max(pos[0] for pos in positions)
                min_y = min(pos[1] for pos in positions)
                max_y = max(pos[1] for pos in positions)
                min_z = min(pos[2] for pos in positions)
                max_z = max(pos[2] for pos in positions)
                
                # è®¡ç®—å„è½´çš„èŒƒå›´
                range_x = max_x - min_x
                range_y = max_y - min_y
                range_z = max_z - min_z
                max_range = max(range_x, range_y, range_z)
                
                processing_log.append(f"ç‰©ä½“ä½ç½®èŒƒå›´: X=[{min_x:.3f}, {max_x:.3f}] ({range_x:.3f}), Y=[{min_y:.3f}, {max_y:.3f}] ({range_y:.3f}), Z=[{min_z:.3f}, {max_z:.3f}] ({range_z:.3f})")
                
                # åªæœ‰å½“ç‰©ä½“ä½ç½®æœ‰æ˜æ˜¾å·®å¼‚æ—¶æ‰è¿›è¡Œå±…ä¸­ï¼ˆé˜ˆå€¼è®¾ä¸º0.01ï¼‰
                if max_range > 0.01:
                    # å°†ç‰©ä½“ä½ç½®å‡å»è´¨å¿ƒ
                    for o in ue_scene["objects"]:
                        original_pos = o["position"].copy()
                        o["position"] = [original_pos[0] - centroid[0],
                                           original_pos[1] - centroid[1],
                                           original_pos[2] - centroid[2]]
                    processing_log.append("å·²å°†æ‰€æœ‰ç‰©ä½“æ•´ä½“å¹³ç§»ï¼Œä½¿è´¨å¿ƒä½äºåŸç‚¹")
                else:
                    processing_log.append("ç‰©ä½“ä½ç½®å·®å¼‚å¾ˆå°ï¼Œè·³è¿‡å±…ä¸­æ“ä½œä»¥é¿å…æ‰€æœ‰ç‰©ä½“é‡å åœ¨åŸç‚¹")
            
            # ç”Ÿæˆæœ€ç»ˆçš„UEåœºæ™¯JSON
            ue_scene_json = json.dumps(ue_scene, indent=2, ensure_ascii=False)
            
            processing_log.append("UEåœºæ™¯é…ç½®ç”Ÿæˆå®Œæˆ!")
            processing_log.append(f"åœºæ™¯åŒ…å«: 1ä¸ªç›¸æœº + {len(ue_scene['objects'])} ä¸ªç‰©ä½“")
            
            return (ue_scene_json,)
                
        except Exception as e:
            error_msg = f"ç”ŸæˆUEåœºæ™¯é…ç½®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg)
            processing_log.append(f"é”™è¯¯: {error_msg}")
            import traceback
            traceback.print_exc()
            return (json.dumps({"error": error_msg}, indent=2),)
    
    def _convert_to_ue_object(self, obj_data: dict, default_rotation: list, 
                             scale_axis: str, scale_multiplier: float,
                             position_axis: str, position_multiplier: float,
                             flip_y_axis: bool, processing_log: list) -> dict:
        """
        å°†å•ä¸ªå¯¹è±¡æ•°æ®è½¬æ¢ä¸ºUEç‰©ä½“æ ¼å¼
        """
        try:
            # è·å–ç‰©ä½“åç§°
            name = obj_data.get("name", "æœªå‘½åç‰©ä½“")
            
            # è·å–ä½ç½®ä¿¡æ¯
            position = obj_data.get("position", [0, 0, 0])
            if not isinstance(position, list) or len(position) != 3:
                processing_log.append(f"ç‰©ä½“ '{name}' ä½ç½®æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ [0, 0, 0]")
                position = [0, 0, 0]
            
            # è·å–æ—‹è½¬ä¿¡æ¯
            rotation = obj_data.get("rotation", default_rotation)
            if not isinstance(rotation, list) or len(rotation) != 3:
                processing_log.append(f"ç‰©ä½“ '{name}' æ—‹è½¬æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_rotation}")
                rotation = default_rotation.copy()
            
            # è·å–ç¼©æ”¾ä¿¡æ¯
            scale = obj_data.get("scale", [1, 1, 1])
            if not isinstance(scale, list) or len(scale) != 3:
                processing_log.append(f"ç‰©ä½“ '{name}' ç¼©æ”¾æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ [1, 1, 1]")
                scale = [1, 1, 1]
            
            # åº”ç”¨ä½ç½®å€æ•°ï¼ˆæŒ‰è½´å‘ï¼‰
            if position_multiplier != 1.0:
                original_pos = position.copy()
                position = self._apply_axis_multiplier(position, position_axis, position_multiplier)
                processing_log.append(f"ç‰©ä½“ '{name}' ä½ç½®{position_axis}è½´åº”ç”¨å€æ•°{position_multiplier}: {original_pos} -> {position}")
            
            # åº”ç”¨ç¼©æ”¾å€æ•°ï¼ˆæŒ‰è½´å‘ï¼‰
            if scale_multiplier != 1.0:
                original_scale = scale.copy()
                scale = self._apply_axis_multiplier(scale, scale_axis, scale_multiplier)
                processing_log.append(f"ç‰©ä½“ '{name}' ç¼©æ”¾{scale_axis}è½´åº”ç”¨å€æ•°{scale_multiplier}: {original_scale} -> {scale}")
            
            # ç¿»è½¬Yè½´ä»¥é€‚é…UEåæ ‡ä½“ç³»
            if flip_y_axis:
                original_y = position[1]
                position[1] = -position[1]
                processing_log.append(f"ç‰©ä½“ '{name}' Yè½´ç¿»è½¬: {original_y} -> {position[1]}")
            
            # åˆ›å»ºUEç‰©ä½“
            ue_object = {
                "name": name,
                "position": [float(position[0]), float(position[1]), float(position[2])],
                "rotation": [float(rotation[0]), float(rotation[1]), float(rotation[2])],
                "scale": [float(scale[0]), float(scale[1]), float(scale[2])]
            }
            
            processing_log.append(f"è½¬æ¢ç‰©ä½“ '{name}': ä½ç½®{position}, æ—‹è½¬{rotation}, ç¼©æ”¾{scale}")
            
            return ue_object
            
        except Exception as e:
            processing_log.append(f"è½¬æ¢ç‰©ä½“å¤±è´¥: {str(e)}")
            return None
    
    def _apply_axis_multiplier(self, values: list, axis: str, multiplier: float) -> list:
        """
        æ ¹æ®è½´å‘é€‰æ‹©å¯¹æŒ‡å®šè½´åº”ç”¨å€æ•°
        
        Args:
            values: ä¸‰ç»´æ•°å€¼åˆ—è¡¨ [X, Y, Z]
            axis: è½´å‘é€‰æ‹© ("XYZ", "X", "Y", "Z", "XY", "XZ", "YZ")
            multiplier: å€æ•°
            
        Returns:
            åº”ç”¨å€æ•°åçš„æ•°å€¼åˆ—è¡¨
        """
        result = values.copy()
        
        if axis == "XYZ":
            # å…¨è½´ç¼©æ”¾
            result = [v * multiplier for v in result]
        elif axis == "X":
            # åªç¼©æ”¾Xè½´
            result[0] *= multiplier
        elif axis == "Y":
            # åªç¼©æ”¾Yè½´
            result[1] *= multiplier
        elif axis == "Z":
            # åªç¼©æ”¾Zè½´
            result[2] *= multiplier
        elif axis == "XY":
            # ç¼©æ”¾Xå’ŒYè½´
            result[0] *= multiplier
            result[1] *= multiplier
        elif axis == "XZ":
            # ç¼©æ”¾Xå’ŒZè½´
            result[0] *= multiplier
            result[2] *= multiplier
        elif axis == "YZ":
            # ç¼©æ”¾Yå’ŒZè½´
            result[1] *= multiplier
            result[2] *= multiplier
        
        return result


# -----------------------------------------------------------------------------
# èŠ‚ç‚¹æ³¨å†Œ
# -----------------------------------------------------------------------------

NODE_CLASS_MAPPINGS = {
    "JSONMerger": JSONMerger,
    "UESceneGenerator": UESceneGenerator,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "JSONMerger": "VVL JSON Merger",
    "UESceneGenerator": "VVL UE Scene Generator",
}

# æ·»åŠ èŠ‚ç‚¹ä¿¡æ¯ï¼Œå¸®åŠ©ComfyUIæ›´å¥½åœ°è¯†åˆ«
__all__ = ["NODE_CLASS_MAPPINGS", "NODE_DISPLAY_NAME_MAPPINGS"] 